# ADHARA
### AI-Powered Learning Friction Detection System

<div align="center">

*Precision AI for early detection of learning difficulties through multimodal behavioral analysis*

[![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-646CFF?style=for-the-badge&logo=vite&logoColor=white)](https://vitejs.dev/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow.js-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white)](https://www.tensorflow.org/js)
[![Ollama](https://img.shields.io/badge/Ollama-000000?style=for-the-badge&logo=ollama&logoColor=white)](https://ollama.ai/)

</div>

---

## ğŸ¯ Overview

**ADHARA** (AI-Driven Holistic Assessment for Developmental Recognition and Assistance) is an intelligent early warning system that detects learning friction patterns in children. By analyzing behavioral signals across multiple modalities, ADHARA helps educators identify potential learning difficulties like **Dyslexia**, **Dyscalculia**, and **ADHD** before they become persistent challenges.

> ğŸ’¡ **Why ADHARA?** Traditional assessments only measure results. ADHARA analyzes the *process* of learningâ€”capturing hesitation, stress, attention patterns, and cognitive load in real-time.

### âœ¨ Key Features

- ğŸ§  **Adaptive Learning Sessions** - Questions adjust in real-time based on performance patterns
- ğŸ‘ï¸ **Face & Emotion Analysis** - Detects stress, confusion, and engagement through webcam
- ğŸ–±ï¸ **Mouse Dynamics Tracking** - Analyzes hesitation, jitter, and interaction velocity
- ğŸ¤ **Speech Analysis** - Monitors fluency, stammering, and verbal hesitation patterns
- ğŸ“Š **AI-Powered Reports** - Generates clinical-grade analysis using local LLM (Ollama)
- ğŸ”’ **Privacy-First** - All processing happens locally, no data leaves the machine

---

## ğŸ“ˆ Multimodal Analysis

ADHARA captures four distinct behavioral streams to create a comprehensive friction profile:

| Data Stream | What We Measure | Technology |
|:------------|:----------------|:-----------|
| **Vision** | Gaze tracking, blink rate, attention drift | face-api.js |
| **Emotion** | Micro-expressions, stress detection, engagement | TensorFlow.js |
| **Motor** | Mouse velocity, hesitation patterns, jitter | Custom tracking |
| **Voice** | Fluency, filler words, stammering, pauses | Web Speech API |

---

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/JithuMon10/ADHARA-AI-Powered-Learning-Friction.git
cd ADHARA-AI-Powered-Learning-Friction

# Install dependencies
cd client
npm install

# Start the development server
npm run dev
```

### AI Analysis (Optional)
For AI-powered report generation, install and run Ollama:
```bash
# Install Ollama from https://ollama.ai
ollama pull llama3.2

# Run with CORS enabled
OLLAMA_ORIGINS="*" ollama serve
```

---

## ğŸ—ï¸ Architecture

```
ADHARA/
â”œâ”€â”€ client/                    # React + Vite frontend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ pages/            # Child activity & Teacher dashboard
â”‚   â”‚   â””â”€â”€ utils/            # Analysis modules
â”‚   â”‚       â”œâ”€â”€ faceAnalysis.js      # Emotion & gaze detection
â”‚   â”‚       â”œâ”€â”€ speechAnalysis.js    # Voice pattern analysis
â”‚   â”‚       â””â”€â”€ disorderDetection.js # Clinical pattern matching
â”‚   â””â”€â”€ public/models/        # TensorFlow face detection models
â”œâ”€â”€ data/                     # Baseline datasets
â””â”€â”€ docs/                     # Documentation
```

---

## ğŸ“Š How It Works

1. **Child Session** - Engaging, game-like activities designed to not feel like tests
2. **Baseline Assessment** - 6-8 questions across cognitive domains (reading, math, attention)
3. **AI Mid-Analysis** - Real-time pattern detection adjusts question flow dynamically
4. **Follow-up Probing** - Targeted questions for areas showing friction
5. **Report Generation** - Comprehensive clinical-grade analysis for educators

---

## ğŸ“ Use Cases

| Application | Description |
|-------------|-------------|
| **Schools** | Early screening for learning difficulties |
| **Special Education** | Progress monitoring and intervention planning |
| **Research** | Behavioral data collection for cognitive studies |
| **Parents** | At-home learning pattern awareness |

---

## ğŸ‘¨â€ğŸ’» Team

<div align="center">

| Jithendra V Anand | Aravind Lal |
|:---:|:---:|
| <img src="https://github.com/JithuMon10.png" width="100" style="border-radius:50%"> | <img src="https://github.com/mfscpayload-690.png" width="100" style="border-radius:50%"> |
| [![GitHub](https://img.shields.io/badge/GitHub-JithuMon10-181717?style=flat&logo=github)](https://github.com/JithuMon10) | [![GitHub](https://img.shields.io/badge/GitHub-mfscpayload--690-181717?style=flat&logo=github)](https://github.com/mfscpayload-690) |
| Lead Developer | Contributor |

</div>

---

## ğŸ“„ License

This project is open-source and available under the MIT License.

---

<div align="center">

**Built with â¤ï¸ for early intervention in education**

â­ **Star this repo if you find it useful!** â­

</div>
